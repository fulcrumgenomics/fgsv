package com.fulcrumgenomics.sv.tools

import com.fulcrumgenomics.FgBioDef.{FilePath, PathToBam}
import com.fulcrumgenomics.bam.api.{QueryType, SamRecord, SamSource}
import com.fulcrumgenomics.commons.util.LazyLogging
import com.fulcrumgenomics.sopt.{arg, clp}
import com.fulcrumgenomics.sv.BreakpointPileup
import com.fulcrumgenomics.sv.cmdline.{ClpGroups, SvTool}
import com.fulcrumgenomics.sv.tools.AggregateSvPileup.PileupGroup
import com.fulcrumgenomics.sv.tools.BreakpointCategory.BreakpointCategory
import com.fulcrumgenomics.util.{Io, Metric}
import htsjdk.samtools.util.{Interval, OverlapDetector}
import htsjdk.tribble.bed.{BEDCodec, BEDFeature}
import htsjdk.tribble.AbstractFeatureReader

import scala.annotation.tailrec
import scala.collection.mutable


@clp(group=ClpGroups.All, description=
  """
    |Merges nearby pileups of reads supporting putative breakpoints.
    |
    |Takes as input the file of pileups produced by `SvPileup`. That file contains a list of breakpoints, each
    |consisting of a chromosome, position and strand for each side of the breakpoint, as well as quantified read support
    |for the breakpoint.
    |
    |This tool merges sets of breakpoints that have their left sides on the same chromosome, their right sides on the
    |same chromosome, the same left and right strands, and their left and right positions both within a length
    |threshold. The merging behavior is transitive. For example, two breakpoints that are farther apart than the length
    |threshold can be merged if there is a third breakpoint that is close to both.
    |
    |`SvPileup` distinguishes between two types of evidence for breakpoint events: split-read evidence, where a
    |breakpoint occurs within a mapped read, and read-pair evidence, where a breakpoint occurs in the unsequenced
    |insert between two paired reads. Currently this tool treats both forms of evidence equally, despite the
    |inaccuracy of positions reported by `SvPileup` for read-pair evidence.
    |
    |If a bam file is provided, each aggregated pileup is annotated with the allele frequency at its left and right
    |breakends. Allele frequency is defined as the total number of templates supporting constituent breakpoints divided
    |by the count of the union of templates that cross any constituent breakends. In particular, paired templates that
    |straddle a breakend are considered to cross the breakend.
    |
    |If a bed file of target regions is provided, each aggregated pileup is annotated with whether its left and
    |right sides overlap a target region.
    |
    |The output file is a tab-delimited table with one record per aggregated cluster of pileups. Aggregated
    |pileups are reported with the minimum and maximum (inclusive) coordinates of all pileups in the cluster, a
    |possible putative structural variant event type supported by the pileups, and the sum of read support from all
    |pileups in the cluster.
    |""")
class AggregateSvPileup
(@arg(flag='i', doc="Input text file of pileups generated by SvPileup") input: FilePath,
 @arg(flag='b', doc="Bam file for allele frequency analysis. Must be the same file that was used as input to SvPileup.")
 bam: Option[PathToBam] = None,
 @arg(flag='f', doc="If bam file is provided: distance upstream and downstream of aggregated breakpoint regions to " +
   "search for mapped templates that overlap breakends. These are the templates that will be partitioned into those " +
   "supporting the breakpoint vs. reading through it for the allele frequency calculation. Recommended to use at " +
   "least the max read pair inner distance used by SvPileup.") flank: Int = 1000,
 @arg(doc="If bam file is provided: minimum total number of templates supporting an aggregated breakpoint to report " +
   "allele frequency. Supports speed improvement by avoiding querying and iterating over huge read pileups that " +
   "contain insufficient support for a breakpoint to be considered interesting.") minBreakpointSupport: Int = 10,
 @arg(doc="If bam file is provided: minimum allele frequency to report. Supports speed improvement by " +
   "avoiding iterating over huge read pileups that contain insufficient support for a breakpoint to be considered " +
   "interesting.") minFrequency: Double = 0.001,
 @arg(flag='t', doc="Optional bed file of target regions") targetsBed: Option[FilePath] = None,
 @arg(flag='o', doc="Output file") output: FilePath,
 @arg(flag='d', doc="Distance threshold below which to cluster breakpoints") maxDist: Int = 10,
) extends SvTool with LazyLogging {

  Io.assertReadable(input)
  Io.assertCanWriteFile(output)

  override def execute(): Unit = {

    // Read pileups from input file
    val pileups: PileupGroup = Metric.read[BreakpointPileup](input).toIndexedSeq
    logger.info(f"Read ${pileups.length} pileups from file $input")

    // Open bam reader
    val samSource: Option[SamSource] = bam.map(SamSource(_))

    // Read targets from bed file and build OverlapDetector
    val targets: Option[OverlapDetector[BEDFeature]] = targetsBed match {
      case None => None
      case Some(bed) =>
        val bedReader = AbstractFeatureReader.getFeatureReader(bed.toAbsolutePath.toString, new BEDCodec(), false)
        val bedFeatures: java.util.List[BEDFeature] = bedReader.iterator().toList
        bedReader.close()
        Some(OverlapDetector.create(bedFeatures))
    }

    // Open output writer
    val writer = Metric.writer[AggregatedBreakpointPileup](output)

    // Group pileups by left and right contig and strand
    pileups.groupBy(_.contigOrientation).foreach { case (_, group) =>

      // Within each contig+strand group, identify all immediate "neighbors" of each pileup (other pileups within the
      // distance threshold)
      val pileupToNeighbors: Map[BreakpointPileup, PileupGroup] = AggregateSvPileup.pileupToNeighbors(group, maxDist)

      // Within each contig+strand group, recursively build (transitive) clusters of neighboring pileups
      val pileupClusters: Seq[PileupGroup] = AggregateSvPileup.toClusters(pileupToNeighbors)
      logger.info(f"Processing ${pileupClusters.size} pileup clusters with endpoints " +
        f"${group.head.left_contig}:${group.head.left_strand}, ${group.head.right_contig}:${group.head.right_strand}")

      // Aggregate each cluster, analyze allele frequency and target overlap, and write output
      pileupClusters
        .map(AggregatedBreakpointPileup.apply)
        .map(_.calculateFrequency(samSource, flank, minBreakpointSupport, minFrequency))
        .map(_.addTargetOverlap(targets))
        .foreach(writer.write)
    }

    writer.close()
  }
}


object AggregateSvPileup {

  /** Type alias for a collection of pileups */
  type PileupGroup = IndexedSeq[BreakpointPileup]

  /**
   * Maps each pileup to the set of other pileups within the distance threshold.
   *
   * Note: it is recommended to call this method on a group of pileups that share a common `BreakpointContigOrientation`
   * to reduce unnecessary run time.
   *
   * @param pileups Set of pileups to evaluate for pairwise neighbor relationships
   * @param maxDist Maximum distance (inclusive) for the left and right coordinates to be considered a neighbor
   * @return Map of pileup to the set of neighbors
   */
  private def pileupToNeighbors(pileups: PileupGroup, maxDist: Int): Map[BreakpointPileup, PileupGroup] = {
    val map: mutable.Map[BreakpointPileup, PileupGroup] = mutable.Map.from(pileups.map((_, IndexedSeq())))
    for (i <- pileups.indices; j <- pileups.indices.drop(i)) {
      val pileup1 = pileups(i)
      val pileup2 = pileups(j)
      if (isCluster(pileup1, pileup2, maxDist)) {
        map.put(pileup1, pileup2 +: map(pileup1))
        map.put(pileup2, pileup1 +: map(pileup2))
      }
    }
    map.toMap
  }

  /** Returns true if the two breakpoints can be clustered, i.e., they are not the same breakpoint (have different
   * IDs), they have the same left and right chromosomes and strand, and the distance between their left and right
   * coordinates is below the threshold (inclusive) */
  private def isCluster(bp1: BreakpointPileup, bp2: BreakpointPileup, maxDist: Int): Boolean = {
    bp1.id != bp2.id &&
      bp1.contigOrientation == bp2.contigOrientation &&
      Math.abs(bp1.left_pos - bp2.left_pos) <= maxDist &&
      Math.abs(bp1.right_pos - bp2.right_pos) <= maxDist
  }

  /**
   * Converts a set of pairwise neighbor relationships to a set of clusters, where each cluster consists of breakpoints
   * that can be joined into a connected path via pairwise neighbor relationships.
   * @param pileupToNeighbors Map of pileup to its set of neighbors
   * @param existingClusters An existing set of clusters to add to
   * @return The set of pileup clusters
   */
  @tailrec
  def toClusters(pileupToNeighbors: Map[BreakpointPileup, PileupGroup],
                 existingClusters: Seq[PileupGroup] = Seq()): Seq[PileupGroup] = {
    pileupToNeighbors.headOption match {
      case None              => existingClusters
      case Some((pileup, _)) =>
        val (pileupGroup, remaining) = extractClusterFor(pileup, pileupToNeighbors, Set.empty)
        toClusters(remaining, existingClusters :+ pileupGroup)
    }
  }

  /**
   * Extracts the complete connected cluster containing the given pileup from the map of pileups to their neighbor sets,
   * and returns the cluster along with the reduced map of pileup to neighbor set such that no remaining pileups in the
   * map belong in a cluster with the returned cluster.
   *
   * Implementation note: the implementation is not tail-recursive, but in practice the recursion depth is small.
   *
   * @param pileup The pileup representative of the cluster that will be returned
   * @param pileupToNeighbors Map of pileup to its set of neighbors
   * @parma neighborsToIgnore Set of pileups to ignore, as they are being considered in parent calls to this method
   * @return (1) The complete cluster for the given pileup; (2) Reduced version of `pileupToNeighbors` with all pileups
   *         in the returned cluster having been removed from both keys and values.
   */
  def extractClusterFor(pileup: BreakpointPileup, pileupToNeighbors: Map[BreakpointPileup, PileupGroup], neighborsToIgnore: Set[BreakpointPileup]):
  (PileupGroup, Map[BreakpointPileup, PileupGroup]) = {
    // Identify the immediate neighbors of the given pileup, and start a cluster containing them
    val neighbors: PileupGroup = pileupToNeighbors.getOrElse(pileup, IndexedSeq()).filter(neighborsToIgnore.contains)
    val currCluster: PileupGroup = neighbors :+ pileup

    // Remove the given pileup from `pileupToNeighbors`
    val reducedRemainingGroups: Map[BreakpointPileup, PileupGroup] = pileupToNeighbors.removed(pileup)

    // Recursively build a cluster consisting of this pileup's immediate neighbors, their immediate neighbors,
    // and so on. With each iteration of the foldLeft operation, we are keeping track of a tuple consisting of
    // (1) a growing connected cluster, and (2) a shrinking map of remaining pileups to their neighbor sets.
    neighbors.foldLeft((currCluster, reducedRemainingGroups)) { case ((currCluster, remaining), nextNeighbor) =>
      val (expandedCluster, reducedRemaining) = extractClusterFor(nextNeighbor, remaining, neighborsToIgnore ++ neighbors.toSet)
      ((currCluster ++ expandedCluster).distinct, reducedRemaining)
    }
  }
}


/** Contig and strand for the left and right sides of a breakpoint pileup */
case class BreakpointContigOrientation(left_contig: String, left_strand: Char, right_contig: String, right_strand: Char)


object BreakpointContigOrientation {
  def apply(pileup: BreakpointPileup): BreakpointContigOrientation = {
    BreakpointContigOrientation(
      left_contig  = pileup.left_contig,
      left_strand  = pileup.left_strand,
      right_contig = pileup.right_contig,
      right_strand = pileup.right_strand,
    )
  }
}


/** Type of structural variant supported by a pileup */
object BreakpointCategory extends Enumeration {
  type BreakpointCategory = String
  val PossibleDeletion = "Possible deletion"
  val IntraContig = "Intra-contig rearrangement"
  val InterContig = "Inter-contig rearrangement"

  def apply(breakpointPileup: BreakpointPileup): BreakpointCategory = {
    if (breakpointPileup.left_contig != breakpointPileup.right_contig) {
      InterContig
    } else {
      if (breakpointPileup.left_strand != breakpointPileup.right_strand) {
        IntraContig
      } else PossibleDeletion
    }
  }
}


/**
 * Aggregated cluster of breakpoint pileups
 * @param id                    Combined ID retaining the IDs of all constituent breakpoints
 * @param category              Breakpoint category
 * @param left_contig           Contig name for left side of breakpoint
 * @param left_min_pos          Minimum coordinate of left breakends
 * @param left_max_pos          Maximum coordinate of left breakends
 * @param left_strand           Strand at left breakends
 * @param right_contig          Contig name for right side of breakpoint
 * @param right_min_pos         Minimum coordinate of right breakends
 * @param right_max_pos         Maximum coordinate of right breakends
 * @param right_strand          Strand at right breakends
 * @param split_reads           Total number of split reads supporting the breakpoints in the cluster
 * @param read_pairs            Total number of read pairs supporting the breakpoints in the cluster
 * @param total                 Total number of templates supporting the breakpoints in the cluster
 * @param left_pileups          List of constituent left breakends
 * @param right_pileups         List of constituent right breakends
 * @param left_frequency        Proportion of templates mapping at one of the left breakends that support a breakpoint.
 *                              If a template maps across multiple breakends, it is only counted once. If a template
 *                              maps entirely between two breakends but does not overlap one, it is not counted. If two
 *                              paired reads straddle a breakend, the template is counted as reading across the
 *                              breakend. If two paired reads both overlap the same breakend, the template is counted
 *                              once.
 * @param right_frequency       Proportion of reads mapping at one of the right breakends that support a breakpoint
 * @param left_overlaps_target  True if the left aggregated region overlaps a target region
 * @param right_overlaps_target True if the right aggregated region overlaps a target region
 */
case class AggregatedBreakpointPileup(id: String,
                                      category: BreakpointCategory,
                                      left_contig: String,
                                      left_min_pos: Int,
                                      left_max_pos: Int,
                                      left_strand: Char,
                                      right_contig: String,
                                      right_min_pos: Int,
                                      right_max_pos: Int,
                                      right_strand: Char,
                                      split_reads: Int,
                                      read_pairs: Int,
                                      total: Int,
                                      left_pileups: PositionList,
                                      right_pileups: PositionList,
                                      left_frequency: Option[Double] = None,
                                      right_frequency: Option[Double] = None,
                                      left_overlaps_target: Boolean = false,
                                      right_overlaps_target: Boolean = false,
                                     ) extends Metric with LazyLogging {

  /** Returns the IDs of constituent breakpoints */
  def pileupIds(): Seq[String] = id.split("_").toSeq.sorted

  /** Returns a new aggregated pileup with the given pileup added */
  def add(pileup: BreakpointPileup): AggregatedBreakpointPileup = {
    assert(pileup.left_contig == left_contig)
    assert(pileup.right_contig == right_contig)
    assert(pileup.left_strand == left_strand)
    assert(pileup.right_strand == right_strand)
    AggregatedBreakpointPileup(
      id              = pileupIds().appended(pileup.id).sorted.mkString("_"),
      category        = category,
      left_contig     = left_contig,
      left_min_pos    = Math.min(left_min_pos, pileup.left_pos),
      left_max_pos    = Math.max(left_max_pos, pileup.left_pos),
      left_strand     = left_strand,
      right_contig    = right_contig,
      right_min_pos   = Math.min(right_min_pos, pileup.right_pos),
      right_max_pos   = Math.max(right_max_pos, pileup.right_pos),
      right_strand    = right_strand,
      split_reads     = split_reads + pileup.split_reads,
      read_pairs      = read_pairs + pileup.read_pairs,
      total           = total + pileup.total,
      left_pileups    = left_pileups.appended(pileup.left_pos),
      right_pileups   = right_pileups.appended(pileup.right_pos),
    )
  }

  /**
   * Returns a new aggregated pileup with left and right frequency populated
   * @param source Optional BAM reader; frequencies are set to None if not provided
   * @param flank Distance upstream and downstream of this aggregated pileup region to query for templates that read
   *              across breakends
   * @param minTotal Minimum total number of templates supporting the aggregated breakpoint in order to calculate
   *                 frequency. Used to speed up execution when the number of supporting templates is too low to be
   *                 interesting.
   * @param minFrequency Minimum proportion of templates overlapping a breakend that support the breakpoint. Used to
   *                     stop iteration over huge sets of overlapping templates when the number of templates supporting
   *                     the breakpoint is insufficient to be interesting. When the number of overlapping templates
   *                     causes (total_supporting_breakpoint / total_overlappers) to drop below this frequency, None is
   *                     returned.
   */
  def calculateFrequency(source: Option[SamSource],
                         flank: Int,
                         minTotal: Int,
                         minFrequency: Double):
  AggregatedBreakpointPileup = {

    def frequency(contig: String, pileups: PositionList, minPos: Int, maxPos: Int): Option[Double] = source match {
      case None => None
      case Some(src) =>
        val numOverlap = numOverlappingTemplates(
          source       = src,
          contig       = contig,
          breakends    = pileups,
          queryMin     = minPos - flank,
          queryMax     = maxPos + flank,
          minTotal     = minTotal,
          minFrequency = minFrequency,
        )
        numOverlap match {
          case None => None
          case Some(n) => Some(total.toDouble / n)
        }
    }

    this.copy(
      left_frequency = frequency(left_contig, left_pileups, left_min_pos, left_max_pos),
      right_frequency = frequency(right_contig, right_pileups, right_min_pos, right_max_pos),
    )
  }

  /**
   * Returns the number of templates that overlap any breakend in the list. Returns None if there are insufficient
   * templates supporting the breakpoint, or if the proportion of those templates that support the breakpoint is less
   * than the minimum frequency.
   * @param source BAM reader
   * @param contig Contig name
   * @param breakends Breakend positions with coordinates defined as in `SvPileup` (1-based)
   * @param queryMin Minimum coordinate to query for overlapping templates (1-based)
   * @param queryMax Maximum coordinate to query for overlapping templates (1-based)
   * @param minTotal Minimum total number of templates supporting the aggregated breakpoint. Used to speed up
   *                 execution when the number of supporting templates is too low to be interesting.
   * @param minFrequency Minimum proportion of templates overlapping a breakend that support the breakpoint. Used to
   *                     stop iteration over huge sets of overlapping templates when the number of templates supporting
   *                     the breakpoint is insufficient to be interesting. When the number of overlapping templates
   *                     causes (total_supporting_breakpoint / total_overlappers) to drop below this frequency, None is
   *                     returned.
   * @return The size of the union of templates that overlap any breakend
   */
  private def numOverlappingTemplates(source: SamSource,
                                      contig: String,
                                      breakends: PositionList,
                                      queryMin: Int,
                                      queryMax: Int,
                                      minTotal: Int,
                                      minFrequency: Double): Option[Int] = {

    if (total < minTotal) return None

    // Read names of overlapping templates
    val overlappers: mutable.Set[String] = new mutable.HashSet[String]()

    // Max number of overlappers; when this number is exceeded (causing the breakpoint frequency to drop below the
    // minimum), None is returned
    val maxOverlappers = total.toDouble / minFrequency

    // Whether to check the full template for overlap including both reads and insert
    def checkAsPair(rec: SamRecord): Boolean = {
      rec.paired &&
        rec.refName == rec.mateRefName &&
        ((rec.start <= rec.mateStart && rec.positiveStrand && rec.mateNegativeStrand)
          || (rec.start >= rec.mateStart && rec.negativeStrand && rec.matePositiveStrand))
    }

    // Iterate over all reads overlapping the region
    val samIter = source.query(contig, queryMin, queryMax, QueryType.Overlapping)
    while (samIter.hasNext) {
      if (overlappers.size > maxOverlappers) {
        samIter.close()
        return None
      }
      val rec = samIter.next()
      if (!overlappers.contains(rec.name)) {
        if (checkAsPair(rec)) {
          if (breakends.positions.exists(
            pos => pos >= Math.min(rec.start, rec.mateStart) && pos <= Math.max(rec.end, rec.mateEnd.get))) {
            overlappers.add(rec.name)
          }
        } else if (breakends.positions.exists(pos => pos >= rec.start && pos <= rec.end)) {
          overlappers.add(rec.name)
        }
      }
    }

    Some(overlappers.size)

  }

  /**
   * Returns a new aggregated pileup with target overlap fields populated
   * @param targets Optional OverlapDetector for target intervals. If None, target overlap fields are set to false.
   */
  def addTargetOverlap(targets: Option[OverlapDetector[BEDFeature]]): AggregatedBreakpointPileup = {
    val (left_overlaps, right_overlaps) = targets match {
      case None => (false, false)
      case Some(t) =>
        (overlapsTarget(left_contig, left_min_pos, left_max_pos, t),
          overlapsTarget(right_contig, right_min_pos, right_max_pos, t))
    }
    this.copy(left_overlaps_target = left_overlaps, right_overlaps_target = right_overlaps)
  }

  private def overlapsTarget(contig: String, start: Int, end: Int, targets: OverlapDetector[BEDFeature]): Boolean = {
    targets.overlapsAny(new Interval(contig, start, end))
  }

}


object AggregatedBreakpointPileup {

  def apply(pileups: PileupGroup): AggregatedBreakpointPileup = {
    pileups match {
      case head +: tail =>
        val headAgg = AggregatedBreakpointPileup(
          id             = head.id,
          category       = BreakpointCategory(head),
          left_contig    = head.left_contig,
          left_min_pos   = head.left_pos,
          left_max_pos   = head.left_pos,
          left_strand    = head.left_strand,
          right_contig   = head.right_contig,
          right_min_pos  = head.right_pos,
          right_max_pos  = head.right_pos,
          right_strand   = head.right_strand,
          split_reads    = head.split_reads,
          read_pairs     = head.read_pairs,
          total          = head.total,
          left_pileups   = PositionList(head.left_pos),
          right_pileups  = PositionList(head.right_pos),
        )
        tail.foldLeft[AggregatedBreakpointPileup](headAgg)((agg, nextPileup) => agg.add(nextPileup))
      case _ => throw new IllegalArgumentException("Pileup group must be non-empty")
    }
  }

}


/** Thin wrapper around a Seq[Int] primarily used to convert back and forth to a string representation */
class PositionList(val positions: Seq[Int]) {
  override def equals(o: Any): Boolean = o match {
    case p: PositionList => p.positions == this.positions
    case _ => false
  }

  override def hashCode(): Int = positions.hashCode()

  override def toString(): String = positions.mkString(",")

  def appended(pos: Int): PositionList = new PositionList(positions.appended(pos).sorted)
}

object PositionList {
  def apply(positions: Int*): PositionList = new PositionList(positions)
  def apply(s: String): PositionList = new PositionList(s.split(",").map(_.toInt))
}
